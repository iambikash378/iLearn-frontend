<section>
    <h2>Backpropagation Basics</h2>
    <p>
      Backpropagation is a supervised learning algorithm used for training artificial neural networks.
      It works by propagating the error from the output layer back through the hidden layers to update the weights using gradient descent.
    </p>
    <p>
      The key steps in backpropagation are:
      <ol>
        <li>Forward pass: compute the output of the neural network.</li>
        <li>Compute loss: measure the difference between predicted and actual values.</li>
        <li>Backward pass: calculate gradients and adjust weights accordingly.</li>
      </ol>
    </p>
    <p>
      Backpropagation has made deep learning possible by enabling multi-layer networks to be trained efficiently.
      It requires differentiable activation functions and benefits from techniques like learning rate tuning and regularization.
    </p>
  </section>
  